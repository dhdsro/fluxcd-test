logging {
  level = "debug"
  format = "logfmt"
}

discovery.kubernetes "pods" {
  role = "pod"
  namespaces {
    names = ["podinfo"]
  }
}

prometheus.scrape "kubernetes_pods" {
  targets    = discovery.kubernetes.pods.targets
  forward_to = [prometheus.remote_write.default.receiver]
  scrape_interval = "30s"

  // Honor Prometheus annotations
  honor_labels = true

  relabel_configs {
    // Keep only pods with prometheus.io/scrape = "true"
    source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
    action        = "keep"
    regex         = "true"
  }

  relabel_configs {
    // Use custom port if prometheus.io/port annotation is present
    source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
    action        = "replace"
    regex         = "([^:]+)(?::\\d+)?;(\\d+)"
    replacement   = "$1:$2"
    target_label  = "__address__"
  }

  relabel_configs {
    // Use custom metrics path if prometheus.io/path annotation is present
    source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
    action        = "replace"
    target_label  = "__metrics_path__"
    regex         = "(.+)"
  }
}

discovery.kubernetes "services" {
  role = "service"
  namespaces {
    names = ["podinfo"]
  }
}

prometheus.scrape "kubernetes_services" {
  targets    = discovery.kubernetes.services.targets
  forward_to = [prometheus.remote_write.default.receiver]
  scrape_interval = "30s"

  // Honor Prometheus annotations
  honor_labels = true

  relabel_configs {
    // Keep only services with prometheus.io/scrape = "true"
    source_labels = ["__meta_kubernetes_service_annotation_prometheus_io_scrape"]
    action        = "keep"
    regex         = "true"
  }

  relabel_configs {
    // Use custom port if prometheus.io/port annotation is present
    source_labels = ["__address__", "__meta_kubernetes_service_annotation_prometheus_io_port"]
    action        = "replace"
    regex         = "([^:]+)(?::\\d+)?;(\\d+)"
    replacement   = "$1:$2"
    target_label  = "__address__"
  }

  relabel_configs {
    // Use custom metrics path if prometheus.io/path annotation is present
    source_labels = ["__meta_kubernetes_service_annotation_prometheus_io_path"]
    action        = "replace"
    target_label  = "__metrics_path__"
    regex         = "(.+)"
  }
}

prometheus.remote_write "default" {
  endpoint {
    url = "http://mimir-distributor.mimir.svc.cluster.local:8080/api/v1/push"
  }

  external_labels = {
    alloy_instance = env("HOSTNAME"),
  }
}

// Kubernetes pod log discovery
discovery.kubernetes "pod_logs" {
  role = "pod"
  namespaces {
    names = ["podinfo", "dhd-cloud", "update-service"]
  }
}

// Collect pod logs
loki.source.kubernetes "pod_logs" {
  targets    = discovery.kubernetes.pod_logs.targets
  forward_to = [loki.process.pod_logs.receiver]
}

// Process pod logs and add labels
loki.process "pod_logs" {
  forward_to = [loki.write.default.receiver]

  // Drop loki-canary logs before processing
  stage.drop {
    expression = "__meta_kubernetes_pod_container_name == \"loki-canary\""
  }

  stage.static_labels {
    values = {
      job = "kubernetes-pods",
    }
  }

  // Extract standard Kubernetes labels
  stage.labels {
    values = {
      namespace   = "__meta_kubernetes_namespace",
      pod         = "__meta_kubernetes_pod_name",
      container   = "__meta_kubernetes_pod_container_name",
      node        = "__meta_kubernetes_pod_node_name",
    }
  }

  // Optional: Parse JSON logs if your apps output JSON
  stage.json {
    expressions = {
      level = "level",
      msg   = "message",
    }
  }

  // Optional: Add timestamp parsing if needed
  stage.timestamp {
    source = "timestamp"
    format = "RFC3339"
  }
}

// Write logs to Loki
loki.write "default" {
  endpoint {
    url = "http://loki-gateway.loki.svc.cluster.local/loki/api/v1/push"
  }

  external_labels = {
    alloy_instance = env("HOSTNAME"),
  }
}

// Traces.

// OTLP receiver for traces (HTTP and gRPC)
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  http {
    endpoint = "0.0.0.0:4318"
  }
  output {
    traces = [otelcol.processor.batch.default.input]
  }
}

// Jaeger receiver (if you have apps using Jaeger format)
otelcol.receiver.jaeger "default" {
  protocols {
    grpc {
      endpoint = "0.0.0.0:14250"
    }
    thrift_http {
      endpoint = "0.0.0.0:14268"
    }
    thrift_compact {
      endpoint = "0.0.0.0:6831"
    }
    thrift_binary {
      endpoint = "0.0.0.0:6832"
    }
  }
  output {
    traces = [otelcol.processor.batch.default.input]
  }
}

// Zipkin receiver (if you have apps using Zipkin format)
otelcol.receiver.zipkin "default" {
  endpoint = "0.0.0.0:9411"
  output {
    traces = [otelcol.processor.batch.default.input]
  }
}

// Batch processor for better performance
otelcol.processor.batch "default" {
  output {
    traces = [otelcol.exporter.otlp.tempo.input]
  }
}

// Export traces to Tempo
otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "http://tempo.tempo.svc.cluster.local:4317"
    tls {
      insecure = true
    }
  }
}
